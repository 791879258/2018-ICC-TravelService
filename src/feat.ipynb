{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_profile_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']]\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    mydf['gender'] = le.fit_transform(df['gender'])\n",
    "\n",
    "    mydf['province'] = le.fit_transform(df['province'])\n",
    "\n",
    "    mydf['age'] = le.fit_transform(df['age'])\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_comment_feature(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    com_rating = df.groupby('userid')['rating'].agg(['sum', 'count']).reset_index()\n",
    "    com_rating.columns = [i if i == 'userid' else 'com_rating_' + i for i in com_rating.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, com_rating, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_order_history_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # type 为 0 和 1 的订单的数量和比率 + 总订单数\n",
    "    ord_hist_ord = df.groupby('userid')['orderType'].agg(['sum', 'count']).reset_index()\n",
    "    ord_hist_ord.columns = ['userid', 'ord_num(type_1)', 'ord_num']\n",
    "    ord_hist_ord['ord_num(type_0)'] = ord_hist_ord['ord_num'] - ord_hist_ord['ord_num(type_1)']\n",
    "    ord_hist_ord['ord_rate(type_1)'] = ord_hist_ord['ord_num(type_1)'] / ord_hist_ord['ord_num']\n",
    "    ord_hist_ord['ord_rate(type_0)'] = ord_hist_ord['ord_num(type_0)'] / ord_hist_ord['ord_num']\n",
    "\n",
    "    # city, country, continent 的数量\n",
    "    addr_count = df.groupby('userid')['city', 'country', 'continent'].count().reset_index()\n",
    "    addr_count.columns = ['userid', 'city_num', 'country_num', 'continent_num']\n",
    "\n",
    "    # type 为 1 的 city, country, continent 的数量\n",
    "    addr_count_pos = df[df['orderType'] == 1].groupby('userid')['city', 'country', 'continent'].count().reset_index()\n",
    "    addr_count_pos.columns = ['userid', 'city_num(type_1)', 'country_num(type_1)', 'continent_num(type_1)']\n",
    "\n",
    "    # 每个 country 的订单数量\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    tmp = lb.fit_transform(df['country'])\n",
    "    tmp_col = ['country_' + str(i) for i in range(tmp.shape[1])]\n",
    "    tmp = pd.DataFrame(tmp, columns=tmp_col)\n",
    "    tmp['userid'] = df['userid'].values\n",
    "    country = tmp.groupby('userid')[tmp_col].agg(['sum']).reset_index()\n",
    "\n",
    "    # 每个 continent 的订单数量\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    tmp = lb.fit_transform(df['continent'])\n",
    "    tmp_col = ['continent_' + str(i) for i in range(tmp.shape[1])]\n",
    "    tmp = pd.DataFrame(tmp, columns=tmp_col)\n",
    "    tmp['userid'] = df['userid'].values\n",
    "    continent = tmp.groupby('userid')[tmp_col].agg(['sum']).reset_index()\n",
    "    \n",
    "    # 最后一次的 order\n",
    "    last_ord = df.groupby('userid').apply(lambda x: x.sort_values('orderTime', ascending=False).head(1)).reset_index(drop=True)[['userid', 'orderid', 'orderTime', 'orderType']]\n",
    "    last_ord.columns = ['userid', 'ord_last_id', 'ord_last_time', 'ord_last_type']\n",
    "    \n",
    "    # 第一次的 order\n",
    "    first_ord = df.groupby('userid').apply(lambda x: x.sort_values('orderTime', ascending=True).head(1)).reset_index(drop=True)[['userid', 'orderid', 'orderTime', 'orderType']]\n",
    "    first_ord.columns = ['userid', 'ord_first_id', 'ord_first_time', 'ord_first_type']\n",
    "    \n",
    "    # type 分别为 0/1 的订单的时间的统计\n",
    "    for t in [0, 1]:\n",
    "        ord_time_stat = df[df['orderType'] == t].groupby('userid')['orderTime'].agg([min, max, np.ptp, np.mean, np.median, np.std]).reset_index()\n",
    "        ord_time_stat.columns = [i if i == 'userid' else 'ord_type%d_time_%s' % (t, i) for i in ord_time_stat.columns]\n",
    "        mydf = pd.merge(mydf, ord_time_stat, on='userid', how='left')\n",
    "    \n",
    "    mydf = pd.merge(mydf, ord_hist_ord, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, addr_count, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, addr_count_pos, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, country, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, continent, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, last_ord, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, first_ord, on='userid', how='left')\n",
    "        \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_order_history_last_w_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # 最后 w 次订单的统计\n",
    "    for w in [2, 3, 4]:\n",
    "        util.log(w)\n",
    "        \n",
    "        last_order = df.groupby('userid').apply(lambda x: x.sort_values('orderTime', ascending=False).head(w)).reset_index(drop=True)[['userid', 'orderTime', 'orderType']]\n",
    "        last_order.columns = ['userid', 'ord_last_time', 'ord_last_type']\n",
    "        \n",
    "        ord_last_time_stat = last_order.groupby('userid')['ord_last_time'].agg([min, max, np.ptp, np.mean, np.median, np.std]).reset_index()\n",
    "        ord_last_time_stat.columns = [i if i == 'userid' else 'ord_last%d_time_%s' % (w, i) for i in ord_last_time_stat.columns]\n",
    "        \n",
    "        ord_last_type_stat = last_order.groupby('userid')['ord_last_type'].agg(['count', sum]).reset_index()\n",
    "        ord_last_type_stat.columns = [i if i == 'userid' else 'ord_last%d_type_%s' % (w, i) for i in ord_last_type_stat.columns]\n",
    "        \n",
    "        mydf = pd.merge(mydf, ord_last_time_stat, on='userid', how='left')\n",
    "        mydf = pd.merge(mydf, ord_last_type_stat, on='userid', how='left')\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_type_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # 每个用户的 action 和 actionType 的数量\n",
    "    act_num = df.groupby(['userid', 'actionType']).size().reset_index().groupby('userid')[0].agg([sum, len]).reset_index()\n",
    "    act_num.columns = ['userid', 'act_num', 'act_type_num']\n",
    "\n",
    "    # 每个类别的数量\n",
    "    act_type_num = df.groupby(['userid', 'actionType']).size().unstack().reset_index()\n",
    "    act_type_num.columns = [i if i == 'userid' else 'act_num(type_' + str(i) + ')' for i in act_type_num.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_num, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, act_type_num, on='userid', how='left')\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_type_based_on_time_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # 最近的一次 action 的 type\n",
    "    act_last_type = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(1)).reset_index(drop=True)[['userid', 'actionType']]\n",
    "    act_last_type.columns = ['userid', 'act_last_type']\n",
    "    \n",
    "    # 最早的一次 action 的 type\n",
    "    act_first_type = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=True).head(1)).reset_index(drop=True)[['userid', 'actionType']]\n",
    "    act_first_type.columns = ['userid', 'act_first_type']\n",
    "\n",
    "    mydf = pd.merge(mydf, act_last_type, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, act_first_type, on='userid', how='left')\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_type_based_on_time_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "\n",
    "    # type 的差值\n",
    "    act_type = tmp.pivot('userid', 'act_time_rank', 'actionType')\n",
    "    act_type = act_type[act_type.columns[::-1]]\n",
    "    act_type_diff = act_type.diff(1, axis=1)\n",
    "    act_type_diff = act_type_diff.iloc[:, 1:].reset_index()\n",
    "    act_type_diff.columns = [i if i == 'userid' else 'act_type_diff(' + str(i) + '-' + str(i + 1) + ')(window_' + str(window) + ')' for i in act_type_diff.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_type_diff, on='userid', how='left')\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_type_num_based_on_time_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "\n",
    "    # 每个类别的数量\n",
    "    act_num_in_window = tmp.groupby(['userid', 'actionType']).size().unstack().reset_index()\n",
    "    act_num_in_window.columns = [i if i == 'userid' else 'act_num(type_' + str(i) + ')(window_' + str(window) + ')' for i in act_num_in_window.columns]\n",
    "    \n",
    "    mydf = pd.merge(mydf, act_num_in_window, on='userid', how='left')\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_type_rate_based_on_time_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "\n",
    "    # 每个类别的列级别的比率\n",
    "    act_column_rate_in_window = tmp.groupby(['userid', 'actionType']).size().unstack().apply(lambda x: x / np.sum(x)).reset_index()\n",
    "    act_column_rate_in_window.columns = [i if i == 'userid' else 'act_column_rate(type_' + str(i) + ')(window_' + str(window) + ')' for i in act_column_rate_in_window.columns]\n",
    "\n",
    "    # 每个类别的行级别的比率\n",
    "    act_row_rate_in_window = tmp.groupby(['userid', 'actionType']).size().unstack().apply((lambda x: x / np.sum(x)), axis=1).reset_index()\n",
    "    act_row_rate_in_window.columns = [i if i == 'userid' else 'act_row_rate(type_' + str(i) + ')(window_' + str(window) + ')' for i in act_row_rate_in_window.columns]\n",
    "    \n",
    "    mydf = pd.merge(mydf, act_column_rate_in_window, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, act_row_rate_in_window, on='userid', how='left')\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_type_row_stat_based_on_time_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "\n",
    "    # 最近的 type 值 + 行级别的统计值\n",
    "    act_type = tmp.pivot('userid', 'act_time_rank', 'actionType')\n",
    "    act_type.columns = ['act_type(rank_' + str(i) + ')(window' + str(window) + ')' for i in act_type.columns]\n",
    "    for i in ['min', 'max', 'mean', 'median', 'std', 'sum', np.ptp]:\n",
    "        act_type['act_row_type_' + i + '(window_' + str(window) + ')' if type(i) == str else 'act_row_type_' + i.func_name + '(window_' + str(window) + ')'] = act_type.apply(i, axis=1)\n",
    "    act_type = act_type.reset_index()\n",
    "    \n",
    "    mydf = pd.merge(mydf, act_type, on='userid', how='left')\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_num_based_on_time_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "\n",
    "    # action 的数量\n",
    "    act_num = tmp.groupby('userid').size().reset_index()\n",
    "    act_num.columns = ['userid', 'act_num(window_%d)' % window]\n",
    "    \n",
    "    mydf = pd.merge(mydf, act_num, on='userid', how='left')\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_type_num_based_on_time_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "\n",
    "    # type 的数量\n",
    "    act_type_num = tmp.groupby(['userid', 'actionType']).size().reset_index().groupby('userid')[0].agg([len]).reset_index()\n",
    "    act_type_num.columns = ['userid', 'act_type_num(window_%d)' % window]\n",
    "    \n",
    "    mydf = pd.merge(mydf, act_type_num, on='userid', how='left')\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_time_based_on_time_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # 最近的一次 action 的 time\n",
    "    act_last_time = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(1)).reset_index(drop=True)[['userid', 'actionTime']]\n",
    "    act_last_time.columns = ['userid', 'act_last_time']\n",
    "    \n",
    "    # 最早的一次 action 的 time\n",
    "    act_first_time = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=True).head(1)).reset_index(drop=True)[['userid', 'actionTime']]\n",
    "    act_first_time.columns = ['userid', 'act_first_time']\n",
    "    \n",
    "    mydf = pd.merge(mydf, act_last_time, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, act_first_time, on='userid', how='left')\n",
    "    \n",
    "    mydf['act_time_last-first'] = mydf['act_last_time'] - mydf['act_first_time']\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_time_based_on_time_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "    \n",
    "    # time 的差值\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime')\n",
    "    act_time = act_time[act_time.columns[::-1]]\n",
    "    act_time_diff = act_time.diff(1, axis=1)\n",
    "    act_time_diff = act_time_diff.iloc[:, 1:].reset_index()\n",
    "    act_time_diff.columns = [i if i == 'userid' else 'act_time_diff(' + str(i) + '-' + str(i + 1) + ')(window_' + str(window) + ')' for i in act_time_diff.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time_diff, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_time_row_stat_based_on_time_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "    \n",
    "    # 最近的 time 值 + 行级别的统计值\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime')\n",
    "    act_time.columns = ['act_time(rank_' + str(i) + ')(window' + str(window) + ')' for i in act_time.columns]\n",
    "    for i in ['min', 'max', 'mean', 'median', 'std', 'sum', np.ptp]:\n",
    "        act_time['act_row_time_' + i + '(window_' + str(window) + ')' if type(i) == str else 'act_row_time_' + i.func_name + '(window_' + str(window) + ')'] = act_time.apply(i, axis=1)\n",
    "    act_time = act_time.reset_index()\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_time_diff2_based_on_time_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "    \n",
    "    # time 的差值\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime')\n",
    "    act_time = act_time[act_time.columns[::-1]]\n",
    "    act_time_diff2 = act_time.diff(2, axis=1)    # need test\n",
    "    act_time_diff2 = act_time_diff2.iloc[:, 2:].reset_index()\n",
    "    act_time_diff2.columns = [i if i == 'userid' else 'act_time_diff2(' + str(i) + '-' + str(i + 2) + ')(window_' + str(window) + ')' for i in act_time_diff2.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time_diff2, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_time_based_on_time_last_window_on_type_feature(df, window, ttype):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    tmp = df[df['actionType'] == ttype].groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "    \n",
    "    # 特定 type 的 action 的 time 的差值\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime')\n",
    "    act_time = act_time[act_time.columns[::-1]]\n",
    "    act_time_diff = act_time.diff(1, axis=1)\n",
    "    act_time_diff = act_time_diff.iloc[:, 1:].reset_index()\n",
    "    act_time_diff.columns = [i if i == 'userid' else 'act_time_diff(%d-%d)(window_%d)(type_%d)' % (i, i+1, window, ttype) for i in act_time_diff.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time_diff, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_time_2order_based_on_time_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "    \n",
    "    # 特定 type 的 action 的 time 的差值\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime')\n",
    "    act_time = act_time[act_time.columns[::-1]]\n",
    "    act_time_diff_2order = act_time.diff(1, axis=1).diff(1, axis=1)\n",
    "    act_time_diff_2order = act_time_diff_2order.iloc[:, 2:].reset_index()\n",
    "    act_time_diff_2order.columns = [i if i == 'userid' else 'act_time_diff_2order(%d-%d)(window_%d)' % (i, i+1, window) for i in act_time_diff_2order.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time_diff_2order, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_real_time_based_on_time_last_window_on_type_feature(df, window, ttype):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    tmp = df[df['actionType'] == ttype].groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "    \n",
    "    # 特定的 type 的 action 的最近的 time 值\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime').reset_index()\n",
    "    act_time.columns = [i if i == 'userid' else 'act_time(rank_%d)(window_%d)(type_%d)' % (i, window, ttype) for i in act_time.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_act_ord_time_diff_feature(act, oord):\n",
    "    act = act.copy()\n",
    "    oord = oord.copy()\n",
    "\n",
    "    mydf = oord[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    ord_time = oord.groupby('userid')['orderTime'].max().reset_index()\n",
    "    act = pd.merge(act, ord_time, on='userid', how='left')  # fillna?\n",
    "    act['act_time-ord_time'] = act['actionTime'] - act['orderTime']\n",
    "    act_ord_time_diff = act[act['act_time-ord_time'] > 0].groupby('userid').size().reset_index()\n",
    "    act_ord_time_diff.columns = ['userid', 'act_ord_time_diff_gt0_count']\n",
    "\n",
    "    mydf = pd.merge(mydf, act_ord_time_diff, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_order_last_order_ydm_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('orderTime', ascending=False).head(1)).reset_index(drop=True)\n",
    "\n",
    "    mydf['ord_last_ord_year'] = pd.to_datetime(tmp['orderTime'], unit='s').dt.year\n",
    "    mydf['ord_last_ord_month'] = pd.to_datetime(tmp['orderTime'], unit='s').dt.month\n",
    "    mydf['ord_last_ord_day'] = pd.to_datetime(tmp['orderTime'], unit='s').dt.day\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_order_type1_ydm_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # 最近一次的 type 为 1 的订单的年月日\n",
    "    tmp = df[df['orderType'] == 1].groupby('userid').apply(lambda x: x.sort_values('orderTime', ascending=False).head(1)).reset_index(drop=True)\n",
    "    mydf['ord_last_type1_year'] = pd.to_datetime(tmp['orderTime'], unit='s').dt.year\n",
    "    mydf['ord_last_type1_month'] = pd.to_datetime(tmp['orderTime'], unit='s').dt.month\n",
    "    mydf['ord_last_type1_day'] = pd.to_datetime(tmp['orderTime'], unit='s').dt.day\n",
    "    \n",
    "    # 最早一次的 type 为 1 的订单的年月日\n",
    "    tmp = df[df['orderType'] == 1].groupby('userid').apply(lambda x: x.sort_values('orderTime', ascending=True).head(1)).reset_index(drop=True)\n",
    "    mydf['ord_first_type1_year'] = pd.to_datetime(tmp['orderTime'], unit='s').dt.year\n",
    "    mydf['ord_first_type1_month'] = pd.to_datetime(tmp['orderTime'], unit='s').dt.month\n",
    "    mydf['ord_first_type1_day'] = pd.to_datetime(tmp['orderTime'], unit='s').dt.day\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_act_ord_act_time_diff_last_window_feature(act, oord, window):\n",
    "    act = act.copy()\n",
    "    oord = oord.copy()\n",
    "\n",
    "    mydf = oord[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    ord_time = oord.groupby('userid')['orderTime'].max().reset_index()\n",
    "    act = pd.merge(act, ord_time, on='userid', how='left')\n",
    "\n",
    "    df = act[act['actionTime'] < act['orderTime']]\n",
    "\n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "\n",
    "    # 最后一次订单之前的 action 的 time 的差值\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime')\n",
    "    act_time = act_time[act_time.columns[::-1]]\n",
    "    act_time_diff = act_time.diff(1, axis=1)\n",
    "    act_time_diff = act_time_diff.iloc[:, 1:].reset_index()\n",
    "    act_time_diff.columns = [i if i == 'userid' else 'act_ord_act_time_diff(' + str(i) + '-' + str(i + 1) + ')(window_' + str(window) + ')' for i in act_time_diff.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time_diff, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_act_ord_type1_act_time_diff_last_window_feature(act, oord, window):\n",
    "    act = act.copy()\n",
    "    oord = oord.copy()\n",
    "\n",
    "    mydf = oord[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    ord_time = oord[oord['orderType'] == 1].groupby('userid')['orderTime'].max().reset_index()\n",
    "    act = pd.merge(act, ord_time, on='userid', how='left')\n",
    "\n",
    "    df = act[act['actionTime'] < act['orderTime']]\n",
    "\n",
    "    tmp = df.groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "\n",
    "    # 最后一次精品订单之前的 action 的 time 的差值\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime')\n",
    "    act_time = act_time[act_time.columns[::-1]]\n",
    "    act_time_diff = act_time.diff(1, axis=1)\n",
    "    act_time_diff = act_time_diff.iloc[:, 1:].reset_index()\n",
    "    act_time_diff.columns = [i if i == 'userid' else 'act_ord_type1_act_time_diff(' + str(i) + '-' + str(i + 1) + ')(window_' + str(window) + ')' for i in act_time_diff.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time_diff, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_sequence_time_diff_feature(df):\n",
    "    df = df.sort_values(by=['userid', 'actionTime'], ascending=[True, False]).copy().reset_index(drop=True)\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    df['actionTimee'] = pd.to_datetime(df['actionTime'], unit='s')\n",
    "    df['actionTimeDiff'] = df['actionTime'].diff()\n",
    "\n",
    "    counter = 1\n",
    "    last_userid = df.iloc[0, 0]\n",
    "    seq_list = []\n",
    "    for i, r in df[['userid', 'actionTimeDiff']].iterrows():\n",
    "        if i % 500000 == 0:\n",
    "            util.log(i)\n",
    "        if r.userid != last_userid:\n",
    "            counter = 1\n",
    "            seq_list.append(counter)\n",
    "            last_userid = r.userid\n",
    "        elif (r.actionTimeDiff <= 0 and r.actionTimeDiff >= -600 or math.isnan(r.actionTimeDiff)) and r.userid == last_userid:\n",
    "            seq_list.append(counter)\n",
    "        else:\n",
    "            counter += 1\n",
    "            seq_list.append(counter)\n",
    "    df['actionSeq'] = pd.Series(seq_list)\n",
    "    \n",
    "    # 基于10分钟分块（时差低于10分钟的行为为一部分），每个块的时差\n",
    "    seq_time_max = df.groupby(['userid', 'actionSeq'])['actionTime'].max().unstack()\n",
    "    seq_time_diff = seq_time_max.diff(1, axis=1)\n",
    "    for window in [2,3,4,5,6,7,10,15]:\n",
    "        tmp = seq_time_diff.iloc[:, 1:(window+1)]\n",
    "        tmp.columns = ['act_seq_time_diff(%d-%d)(window_%d)' % (i, i-1, window) for i in tmp.columns]\n",
    "        tmp = tmp.reset_index()\n",
    "        data = pd.merge(mydf, tmp, on='userid', how='left')\n",
    "        util.log('window=%d' % window)\n",
    "        data.to_csv('../data/output/feat/%s%d' % ('action_sequence_time_diff_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_sequence_time_stat_feature(df):\n",
    "    df = df.sort_values(by=['userid', 'actionTime'], ascending=[True, False]).copy().reset_index(drop=True)\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    df['actionTimee'] = pd.to_datetime(df['actionTime'], unit='s')\n",
    "    df['actionTimeDiff'] = df['actionTime'].diff()\n",
    "\n",
    "    counter = 1\n",
    "    last_userid = df.iloc[0, 0]\n",
    "    seq_list = []\n",
    "    for i, r in df[['userid', 'actionTimeDiff']].iterrows():\n",
    "        if i % 500000 == 0:\n",
    "            util.log(i)\n",
    "        if r.userid != last_userid:\n",
    "            counter = 1\n",
    "            seq_list.append(counter)\n",
    "            last_userid = r.userid\n",
    "        elif (r.actionTimeDiff <= 0 and r.actionTimeDiff >= -600 or math.isnan(r.actionTimeDiff)) and r.userid == last_userid:\n",
    "            seq_list.append(counter)\n",
    "        else:\n",
    "            counter += 1\n",
    "            seq_list.append(counter)\n",
    "    df['actionSeq'] = pd.Series(seq_list)\n",
    "    \n",
    "    time_stat = df[(df['actionSeq'] == 1) | (df['actionSeq'] == 2) | (df['actionSeq'] == 3)].groupby(['userid', 'actionSeq'])['actionTime'].agg([min, max, np.mean, np.median, np.ptp, np.std, 'count']).unstack().reset_index()\n",
    "    time_stat.columns = ['userid' if i[0] == 'userid' else 'act_seq_time_stat_%s_last%d' % (i[0], i[1]) for i in time_stat.columns]\n",
    "    \n",
    "    time_stat.to_csv('../data/output/feat/%s' % ('action_sequence_time_stat_last123'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_time_diff_234_56789_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # 234 类型的 action 的 time 的差值\n",
    "    tmp = df[df['actionType'].isin([2, 3, 4])].groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime')\n",
    "    act_time = act_time[act_time.columns[::-1]]\n",
    "    act_time_diff_234 = act_time.diff(1, axis=1)\n",
    "    act_time_diff_234 = act_time_diff_234.iloc[:, 1:].reset_index()\n",
    "    act_time_diff_234.columns = [i if i == 'userid' else 'act_time_diff_234(' + str(i) + '-' + str(i + 1) + ')(window_' + str(window) + ')' for i in act_time_diff_234.columns]\n",
    "    \n",
    "    # 56789 类型的 action 的 time 的差值\n",
    "    tmp = df[df['actionType'].isin([5, 6, 7, 8, 9])].groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(window)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime')\n",
    "    act_time = act_time[act_time.columns[::-1]]\n",
    "    act_time_diff_56789 = act_time.diff(1, axis=1)\n",
    "    act_time_diff_56789 = act_time_diff_56789.iloc[:, 1:].reset_index()\n",
    "    act_time_diff_56789.columns = [i if i == 'userid' else 'act_time_diff_56789(' + str(i) + '-' + str(i + 1) + ')(window_' + str(window) + ')' for i in act_time_diff_56789.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time_diff_234, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, act_time_diff_56789, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_stat_last_every_type_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # 离最近的 123456789 的 action 的时间的统计\n",
    "    for t in range(1, 10):\n",
    "        tmp = df[df['actionType'] == t].groupby('userid')['actionTime'].agg([min, max, np.ptp, np.std, np.mean, np.median, 'count']).reset_index()\n",
    "        tmp.columns = [i if i == 'userid' else 'act_time_%s(type_%d)' % (i, t) for i in tmp.columns]\n",
    "        \n",
    "        mydf = pd.merge(mydf, tmp, on='userid', how='left')\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_act_ord_before_type1_stat_feature(act, oord):\n",
    "    act = act.copy()\n",
    "    oord = oord.copy()\n",
    "\n",
    "    mydf = oord[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    ord_time = oord[oord['orderType'] == 1].groupby('userid')['orderTime'].max().reset_index()\n",
    "    act = pd.merge(act, ord_time, on='userid', how='left')\n",
    "\n",
    "    df = act[act['actionTime'] < act['orderTime']]\n",
    "\n",
    "    act_time_stat = df.groupby('userid')['actionTime'].agg([min, max, np.ptp, np.std, np.mean, np.median, 'count']).reset_index()\n",
    "    act_time_stat.columns = [i if i == 'userid' else 'act_ord_before_type1_act_time_%s' % i for i in act_time_stat.columns]\n",
    "    \n",
    "    act_type_size = mydf.copy()\n",
    "    for t in range(1, 10):\n",
    "        tmp = df[df['actionType'] == t].groupby('userid').size().reset_index()\n",
    "        tmp.columns = ['userid', 'act_ord_before_type1_act_type_size(type_%d)' % t]\n",
    "        act_type_size = pd.merge(act_type_size, tmp, on='userid', how='left')\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time_stat, on='userid', how='left')\n",
    "    mydf = pd.merge(mydf, act_type_size, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_time_diff_stat_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    df = df.sort_values(['userid', 'actionTime']).reset_index(drop=True).copy()\n",
    "    df['actionTimeDiff'] = df['actionTime'].diff(1)\n",
    "    df = df.groupby('userid').apply(lambda x: x.iloc[1:, :]).reset_index(drop=True)\n",
    "\n",
    "    act_time_diff_stat = df.groupby('userid')['actionTimeDiff'].agg([min, max, np.mean, np.median, np.std, sum]).reset_index()\n",
    "    act_time_diff_stat.columns = [i if i == 'userid' else 'act_time_diff_%s' % i for i in act_time_diff_stat.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time_diff_stat, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_time_diff_stat_last_window_feature(df, window):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    df = df.sort_values(['userid', 'actionTime']).reset_index(drop=True).copy()\n",
    "    df['actionTimeDiff'] = df['actionTime'].diff(1)\n",
    "    df = df.groupby('userid').apply(lambda x: x.iloc[1:, :]).reset_index(drop=True)\n",
    "    \n",
    "    tmp = df.groupby('userid').apply(lambda x: x.iloc[:-window, :]).reset_index(drop=True)\n",
    "    act_time_diff_stat = tmp.groupby('userid')['actionTimeDiff'].agg([min, max, np.mean, np.median, np.std, sum]).reset_index()\n",
    "    act_time_diff_stat.columns = [i if i == 'userid' else 'act_time_diff_%s(window_%d)' % (i, window) for i in act_time_diff_stat.columns]\n",
    "\n",
    "    mydf = pd.merge(mydf, act_time_diff_stat, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_time_last_on_every_type_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    df = df.sort_values(['userid', 'actionTime'], ascending=[True, False]).reset_index(drop=True).copy()\n",
    "    for t in range(1, 10):\n",
    "        act_time = df[df['actionType'] == t].groupby('userid').apply(lambda x: x.head(1)).reset_index(drop=True)\n",
    "        act_time = act_time[['userid', 'actionTime']]\n",
    "        act_time.columns = ['userid', 'act_time_last(type_%d)' % t]\n",
    "        \n",
    "        mydf = pd.merge(mydf, act_time, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_try_feat(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    mydf = df[['userid']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    df = df.sort_values(['userid', 'actionTime'], ascending=[True, False]).reset_index(drop=True).copy()\n",
    "    \n",
    "    last_5 = df[df.actionType == 5].drop_duplicates(subset=['userid'])\n",
    "    last_6 = df[df.actionType == 6].drop_duplicates(subset=['userid'])\n",
    "    time_gap_last56 = pd.merge(last_5, last_6, on='userid', how='outer')\n",
    "    time_gap_last56['time_gap_last56'] = time_gap_last56.actionTime_y - time_gap_last56.actionTime_x\n",
    "    mydf = pd.merge(mydf, time_gap_last56[['userid', 'time_gap_last56']], on='userid', how='left')\n",
    "\n",
    "    tmp = df[df['actionType'] == 5].groupby('userid').apply(lambda x: x.sort_values('actionTime', ascending=False).head(2)).reset_index(drop=True)\n",
    "    tmp['act_time_rank'] = tmp.groupby('userid')['actionTime'].rank(method = 'first', ascending=False).astype(int)\n",
    "    act_time = tmp.pivot('userid', 'act_time_rank', 'actionTime')\n",
    "    act_time = act_time[act_time.columns[::-1]]\n",
    "    act_time_diff = act_time.diff(1, axis=1)\n",
    "    act_time_diff = act_time_diff.iloc[:, 1:].reset_index()\n",
    "    act_time_diff.columns = [i if i == 'userid' else 'act_time_diff(%d-%d)(window_%d)(type_%d)' % (i, i+1, 2, 5) for i in act_time_diff.columns]\n",
    "    mydf = pd.merge(mydf, act_time_diff, on='userid', how='left')\n",
    "\n",
    "    last_6 = df[df.actionType == 6].drop_duplicates(subset=['userid'])\n",
    "    last_7 = df[df.actionType == 7].drop_duplicates(subset=['userid'])\n",
    "    time_gap_last67 = pd.merge(last_6, last_7, on='userid', how='outer')\n",
    "    time_gap_last67['time_gap_last67'] = time_gap_last67.actionTime_y - time_gap_last67.actionTime_x\n",
    "    mydf = pd.merge(mydf, time_gap_last67[['userid', 'time_gap_last67']], on='userid', how='left')\n",
    "\n",
    "    df['actionDate'] = pd.to_datetime(df['actionTime'], unit='s')\n",
    "    df = pd.merge(df, df.drop_duplicates(subset=['userid'])[['userid', 'actionDate']], on='userid', how='left')\n",
    "    df['lastDay'] = df.actionDate_x.dt.day == df.actionDate_y.dt.day\n",
    "    last_day = df[df.lastDay].groupby('userid')['lastDay'].size().reset_index()\n",
    "    last_day_5 = df[df.lastDay & (df.actionType == 5)].groupby('userid')['lastDay'].size().reset_index()\n",
    "    tmp = pd.merge(last_day, last_day_5, on='userid', how='left')\n",
    "    tmp['last_day_rate(type_5)'] = tmp.lastDay_y / tmp.lastDay_x\n",
    "    mydf = pd.merge(mydf, tmp[['userid', 'last_day_rate(type_5)']], on='userid', how='left')\n",
    "\n",
    "    last_time = df.drop_duplicates(subset=['userid'])[['userid', 'actionTime']]\n",
    "    last_time.columns = ['userid', 'last_time']\n",
    "    mydf = pd.merge(mydf, last_time, on='userid', how='left')\n",
    "\n",
    "    last_4 = df[df.actionType == 4].drop_duplicates(subset=['userid'])\n",
    "    last_5 = df[df.actionType == 5].drop_duplicates(subset=['userid'])\n",
    "    time_gap_last45 = pd.merge(last_4, last_5, on='userid', how='outer')\n",
    "    time_gap_last45['time_gap_last45'] = time_gap_last45.actionTime_y - time_gap_last45.actionTime_x\n",
    "    mydf = pd.merge(mydf, time_gap_last45[['userid', 'time_gap_last45']], on='userid', how='left')\n",
    "\n",
    "    last_1 = df[df.actionType == 1].drop_duplicates(subset=['userid'])\n",
    "    last = df.drop_duplicates(subset=['userid'])\n",
    "    time_gap_last1 = pd.merge(last_1, last, on='userid', how='outer')\n",
    "    time_gap_last1['time_gap_last1'] = time_gap_last1.actionTime_y - time_gap_last1.actionTime_x\n",
    "    mydf = pd.merge(mydf, time_gap_last1[['userid', 'time_gap_last1']], on='userid', how='left')\n",
    "\n",
    "    last_5 = df[df.actionType == 5].drop_duplicates(subset=['userid'])\n",
    "    last = df.drop_duplicates(subset=['userid'])\n",
    "    time_gap_last5 = pd.merge(last_5, last, on='userid', how='outer')\n",
    "    time_gap_last5['time_gap_last5'] = time_gap_last5.actionTime_y - time_gap_last5.actionTime_x\n",
    "    mydf = pd.merge(mydf, time_gap_last5[['userid', 'time_gap_last5']], on='userid', how='left')\n",
    "\n",
    "    last_6 = df[df.actionType == 6].drop_duplicates(subset=['userid'])\n",
    "    last = df.drop_duplicates(subset=['userid'])\n",
    "    time_gap_last6 = pd.merge(last_6, last, on='userid', how='outer')\n",
    "    time_gap_last6['time_gap_last6'] = time_gap_last6.actionTime_y - time_gap_last6.actionTime_x\n",
    "    mydf = pd.merge(mydf, time_gap_last6[['userid', 'time_gap_last6']], on='userid', how='left')\n",
    "\n",
    "    tmp = df[df.actionType.isin([5, 6])].copy()\n",
    "    tmp['actionTimeDiff'] = tmp['actionTime'].diff(1)\n",
    "    tmp = tmp.groupby('userid').apply(lambda x: x.iloc[1:, :]).reset_index(drop=True)\n",
    "    act_time_diff_stat = tmp.groupby('userid')['actionTimeDiff'].agg([min, max, np.mean, np.median, np.std, sum]).reset_index()\n",
    "    act_time_diff_stat.columns = [i if i == 'userid' else 'act_time_diff_56_%s' % i for i in act_time_diff_stat.columns]\n",
    "    mydf = pd.merge(mydf, act_time_diff_stat, on='userid', how='left')\n",
    "    \n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_tr = pd.read_csv('../data/input/train/action_train.csv')  # 用户行为数据\n",
    "order_future_tr = pd.read_csv('../data/input/train/orderFuture_train.csv')  # 待预测数据\n",
    "order_history_tr = pd.read_csv('../data/input/train/orderHistory_train.csv')  # 用户历史订单数据\n",
    "user_comment_tr = pd.read_csv('../data/input/train/userComment_train.csv')  # 用户评论数据\n",
    "user_profile_tr = pd.read_csv('../data/input/train/userProfile_train.csv')  # 用户个人信息\n",
    "\n",
    "action_te = pd.read_csv('../data/input/test/action_test.csv')\n",
    "order_future_te = pd.read_csv('../data/input/test/orderFuture_test.csv')\n",
    "order_history_te = pd.read_csv('../data/input/test/orderHistory_test.csv')\n",
    "user_comment_te = pd.read_csv('../data/input/test/userComment_test.csv')\n",
    "user_profile_te = pd.read_csv('../data/input/test/userProfile_test.csv')\n",
    "\n",
    "action = pd.concat([action_tr, action_te], axis=0).reset_index(drop=True)\n",
    "order_history = pd.concat([order_history_tr, order_history_te], axis=0).reset_index(drop=True)\n",
    "user_comment = pd.concat([user_comment_tr, user_comment_te], axis=0).reset_index(drop=True)\n",
    "user_profile = pd.concat([user_profile_tr, user_profile_te], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_profile_feat = get_user_profile_feature(user_profile)\n",
    "user_profile_feat.to_csv('../data/output/feat/%s' % 'user_profile', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_comment_feat = get_user_comment_feature(user_comment)\n",
    "user_comment_feat.to_csv('../data/output/feat/%s' % 'user_comment', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_history_feat = get_order_history_feature(order_history)\n",
    "order_history_feat.to_csv('../data/output/feat/%s' % 'order_history', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_history_last_w_feat = get_order_history_last_w_feature(order_history)\n",
    "order_history_last_w_feat.to_csv('../data/output/feat/%s' % 'order_history_last_w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_type_feat = get_action_type_feature(action)\n",
    "action_type_feat.to_csv('../data/output/feat/%s' % 'action_type', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_type_based_on_time_feat = get_action_type_based_on_time_feature(action)\n",
    "action_type_based_on_time_feat.to_csv('../data/output/feat/%s' % 'action_type_based_on_time', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for window in [3,4,5,6,7]:\n",
    "    util.log(window)\n",
    "    action_type_based_on_time_last_window_feat = get_action_type_based_on_time_last_window_feature(action, window)\n",
    "    action_type_based_on_time_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_type_based_on_time_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for window in [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20]:\n",
    "    util.log(window)\n",
    "    action_type_num_based_on_time_last_window_feat = get_action_type_num_based_on_time_last_window_feature(action, window)\n",
    "    action_type_num_based_on_time_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_type_num_based_on_time_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20]:\n",
    "    util.log(window)\n",
    "    action_type_rate_based_on_time_last_window_feat = get_action_type_rate_based_on_time_last_window_feature(action, window)\n",
    "    action_type_rate_based_on_time_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_type_rate_based_on_time_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [6]:\n",
    "    util.log(window)\n",
    "    action_type_row_stat_based_on_time_last_window_feat = get_action_type_row_stat_based_on_time_last_window_feature(action, window)\n",
    "    action_type_row_stat_based_on_time_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_type_row_stat_based_on_time_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [4, 7, 13, 17, 20, 25, 30]:\n",
    "    util.log(window)\n",
    "    action_num_based_on_time_last_window_feat = get_action_num_based_on_time_last_window_feature(action, window)\n",
    "    action_num_based_on_time_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_num_based_on_time_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [4, 7, 13, 17, 20, 25, 30]:\n",
    "    util.log(window)\n",
    "    action_type_num_based_on_time_last_window_feat = get_action_type_num_based_on_time_last_window_feature(action, window)\n",
    "    action_type_num_based_on_time_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_type_num_based_on_time_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_time_based_on_time_feat = get_action_time_based_on_time_feature(action)\n",
    "action_time_based_on_time_feat.to_csv('../data/output/feat/%s' % 'action_time_based_on_time', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [6]:\n",
    "    util.log(window)\n",
    "    action_time_based_on_time_last_window_feat = get_action_time_based_on_time_last_window_feature(action, window)\n",
    "    action_time_based_on_time_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_time_based_on_time_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [3, 6, 10, 14]:\n",
    "    util.log(window)\n",
    "    action_time_row_stat_based_on_time_last_window_feat = get_action_time_row_stat_based_on_time_last_window_feature(action, window)\n",
    "    action_time_row_stat_based_on_time_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_time_row_stat_based_on_time_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [3, 4, 5, 6, 7, 8]:\n",
    "    util.log(window)\n",
    "    action_time_diff2_based_on_time_last_window_feat = get_action_time_diff2_based_on_time_last_window_feature(action, window)\n",
    "    action_time_diff2_based_on_time_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_time_diff2_based_on_time_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ttype in [1,5,6,7,8,9]:\n",
    "    for window in [6]:\n",
    "        util.log('type=%d window=%d' % (ttype, window))\n",
    "        action_time_based_on_time_last_window_on_type_feat = get_action_time_based_on_time_last_window_on_type_feature(action, window, ttype)\n",
    "        action_time_based_on_time_last_window_on_type_feat.to_csv('../data/output/feat/%s%d%s%d' % ('action_time_based_on_time_last_window', window, '_on_type', ttype), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    util.log(window)\n",
    "    action_time_2order_based_on_time_last_window_feat = get_action_time_2order_based_on_time_last_window_feature(action, window)\n",
    "    action_time_2order_based_on_time_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_time_2order_based_on_time_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ttype in [1,5,6,7,8,9]:\n",
    "    for window in [4, 7, 10]:\n",
    "        util.log('type=%d window=%d' % (ttype, window))\n",
    "        action_real_time_based_on_time_last_window_on_type_feat = get_action_real_time_based_on_time_last_window_on_type_feature(action, window, ttype)\n",
    "        action_real_time_based_on_time_last_window_on_type_feat.to_csv('../data/output/feat/%s%d%s%d' % ('action_real_time_based_on_time_last_window', window, '_on_type', ttype), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_ord_time_diff_feat = get_act_ord_time_diff_feature(action, order_history)\n",
    "act_ord_time_diff_feat.to_csv('../data/output/feat/%s' % 'action_order_time_diff', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_last_order_ydm_feat = get_order_last_order_ydm_feature(order_history)\n",
    "order_last_order_ydm_feat.to_csv('../data/output/feat/%s' % 'order_last_order_ydm', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_type1_ydm_feat = get_order_type1_ydm_feature(order_history)\n",
    "order_type1_ydm_feat.to_csv('../data/output/feat/%s' % 'order_type1_ydm', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [7,8,10,11]:\n",
    "    util.log(window)\n",
    "    act_ord_act_time_diff_last_window_feat = get_act_ord_act_time_diff_last_window_feature(action, order_history, window)\n",
    "    act_ord_act_time_diff_last_window_feat.to_csv('../data/output/feat/%s%d' % ('act_ord_act_time_diff_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [2,4]:\n",
    "    util.log(window)\n",
    "    act_ord_type1_act_time_diff_last_window_feat = get_act_ord_type1_act_time_diff_last_window_feature(action, order_history, window)\n",
    "    act_ord_type1_act_time_diff_last_window_feat.to_csv('../data/output/feat/%s%d' % ('act_ord_type1_act_time_diff_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_action_sequence_time_diff_feature(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_action_sequence_time_stat_feature(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [6]:\n",
    "    util.log(window)\n",
    "    action_time_diff_234_56789_last_window_feat = get_action_time_diff_234_56789_last_window_feature(action, window)\n",
    "    action_time_diff_234_56789_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_time_diff_234_56789_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_stat_last_every_type_feat = get_action_stat_last_every_type_feature(action)\n",
    "action_stat_last_every_type_feat.to_csv('../data/output/feat/%s' % 'action_stat_last_every_type', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_ord_before_type1_stat_feat = get_act_ord_before_type1_stat_feature(action, order_history)\n",
    "act_ord_before_type1_stat_feat.to_csv('../data/output/feat/%s' % 'act_ord_before_type1_stat', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_time_diff_stat_feat = get_action_time_diff_stat_feature(action)  # untest\n",
    "action_time_diff_stat_feat.to_csv('../data/output/feat/%s' % 'action_time_diff_stat', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for window in [3, 4, 5, 6, 7, 8, 9]:\n",
    "    util.log(window)\n",
    "    action_time_diff_stat_last_window_feat = get_action_time_diff_stat_last_window_feature(action, window)\n",
    "    action_time_diff_stat_last_window_feat.to_csv('../data/output/feat/%s%d' % ('action_time_diff_stat_last_window', window), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_time_last_on_every_type_feat = get_action_time_last_on_every_type_feature(action)\n",
    "action_time_last_on_every_type_feat.to_csv('../data/output/feat/%s' % 'action_time_last_on_every_type', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try_feat = get_try_feat(action)\n",
    "try_feat.to_csv('../data/output/feat/%s' % 'try', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
