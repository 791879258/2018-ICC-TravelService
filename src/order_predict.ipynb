{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_tr = pd.read_csv('../data/input/train/action_train.csv')  # 用户行为数据\n",
    "order_future_tr = pd.read_csv('../data/input/train/orderFuture_train.csv')  # 待预测数据\n",
    "order_history_tr = pd.read_csv('../data/input/train/orderHistory_train.csv')  # 用户历史订单数据\n",
    "user_comment_tr = pd.read_csv('../data/input/train/userComment_train.csv')  # 用户评论数据\n",
    "user_profile_tr = pd.read_csv('../data/input/train/userProfile_train.csv')  # 用户个人信息\n",
    "\n",
    "action_te = pd.read_csv('../data/input/test/action_test.csv')\n",
    "order_future_te = pd.read_csv('../data/input/test/orderFuture_test.csv')\n",
    "order_history_te = pd.read_csv('../data/input/test/orderHistory_test.csv')\n",
    "user_comment_te = pd.read_csv('../data/input/test/userComment_test.csv')\n",
    "user_profile_te = pd.read_csv('../data/input/test/userProfile_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_date(date):\n",
    "    year = int(date[:4])\n",
    "    month = int(date[-2:])\n",
    "    return (year - 2010) * 12 + month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_time_gap(t):\n",
    "    s = '2018-01-01'\n",
    "    return time.mktime(datetime.datetime.strptime(s, \"%Y-%m-%d\").timetuple()) - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_interaction_feature(df, feature_A, feature_B):\n",
    "    feature_A_list = sorted(df[feature_A].unique())\n",
    "    feature_B_list = sorted(df[feature_B].unique())\n",
    "    count = 0\n",
    "    mydict = {}\n",
    "    for i in feature_A_list:\n",
    "        mydict[int(i)] = {}\n",
    "        for j in feature_B_list:\n",
    "            mydict[int(i)][int(j)] = count\n",
    "            count += 1\n",
    "    return df.apply(lambda x: mydict[int(x[feature_A])][int(x[feature_B])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_label_encoder_mapping(le):\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    for k, v in le_name_mapping.items():\n",
    "        print str(k) + ': ' + str(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_profile_feature(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    mydf = df[['userid']]\n",
    "    le = preprocessing.LabelEncoder()\n",
    "#     mydf['gender'] = le.fit_transform(df['gender'])\n",
    "\n",
    "    mydf['province'] = le.fit_transform(df['province'])\n",
    "\n",
    "    mydf['age'] = le.fit_transform(df['age'])\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action_feature(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 没包含\n",
    "    mydf = df.groupby('userid').size().reset_index()\n",
    "    mydf.columns = ['userid', 'action_num']\n",
    "\n",
    "    act_type_last = mydf[['userid']]\n",
    "    for i in [1, 2, 3]:\n",
    "        tmp = df.groupby('userid').nth(-i)['actionType'].reset_index()\n",
    "        tmp.columns = ['userid', 'act_type_last' + str(i)]\n",
    "        act_type_last = pd.merge(act_type_last, tmp, how='left', on='userid')\n",
    "\n",
    "    act_type_first1 = df.groupby('userid').nth(1)['actionType'].reset_index()\n",
    "    act_type_first1.columns = ['userid', 'act_type_first1']\n",
    "\n",
    "    time_gap_stat = cal_time_gap(df['actionTime']).groupby(df['userid']).agg([np.mean, np.std, min]).reset_index()\n",
    "    time_gap_stat.columns = ['userid', 'action_time_gap_mean', 'action_time_gap_std', 'action_time_gap_min']\n",
    "\n",
    "    time_gap_last = mydf[['userid']]\n",
    "    for i in [1, 2, 3, 4]:\n",
    "        tmp = cal_time_gap(df['actionTime']).groupby(df['userid']).nth(-i).reset_index()\n",
    "        tmp.columns = ['userid', 'time_gap_last' + str(i)]\n",
    "        time_gap_last = pd.merge(time_gap_last, tmp, how='left', on='userid')\n",
    "\n",
    "    time_gap_first1 = cal_time_gap(df['actionTime']).groupby(df['userid']).nth(1).reset_index()\n",
    "    time_gap_first1.columns = ['userid', 'time_gap_first1']\n",
    "\n",
    "    time_gap_last123 = cal_time_gap(df['actionTime']).groupby(df['userid']).nth([-1, -2, -3]).reset_index()\n",
    "    time_gap_last123_stat = time_gap_last123.groupby('userid')['actionTime'].agg([np.mean, np.std]).reset_index()\n",
    "    time_gap_last123_stat.columns = ['userid', 'time_gap_last123_mean', 'time_gap_last123_std']\n",
    "\n",
    "    df['dist'] = df.groupby('userid')['actionTime'].rank(ascending=False)\n",
    "    dist = mydf[['userid']]\n",
    "    for i in [9, 3, 5, 8]:\n",
    "        tmp = df[df['actionType'] == i].groupby('userid')['dist'].nth(-1).reset_index()\n",
    "        tmp.columns = ['userid', 'dist' + str(i)]\n",
    "        dist = pd.merge(dist, tmp, how='left', on='userid')\n",
    "\n",
    "    time_gap_all_type = mydf[['userid']]\n",
    "    for i in range(1, 10):\n",
    "        tmp = df[df['actionType'] == i].groupby('userid')['actionTime'].nth(-1).reset_index()\n",
    "        tmp['actionTime'] = cal_time_gap(tmp['actionTime'])\n",
    "        tmp.columns = ['userid', 'time_gap' + str(i)]\n",
    "        time_gap_all_type = pd.merge(time_gap_all_type, tmp, how='left', on='userid')\n",
    "\n",
    "    # 构建时间间隔序列 time_gap\n",
    "    sub = df.loc[:(len(df) - 2), 'actionTime']  # 构建减数 Serise\n",
    "    sub.index = sub.index + 1  # 索引加一\n",
    "    df['time_gap'] = df.loc[1:, 'actionTime'] - sub  # 计算时间间隔\n",
    "    tmp = df.groupby('userid').nth(0).reset_index()  # 找到用户的第一个 action\n",
    "    tmp['time_gap'] = 0  # 把所有用户的第一个 action 的 time_gap 赋 0\n",
    "    df = pd.merge(df, tmp, how='left', on=['userid', 'actionTime', 'actionType', 'dist']).fillna(1)  # merge 起来后，空值填充 1\n",
    "    df['time_gap'] = df['time_gap_x'] * df['time_gap_y']  # 两列相乘，将所有用户的第一个 action 的 time_gap 赋 0\n",
    "    df = df.drop(['time_gap_x', 'time_gap_y'], axis=1)  # 移除多余的列\n",
    "    df = df.replace(0, np.nan)  # 0 -> NaN\n",
    "\n",
    "    time_gap_seq_stat = mydf[['userid']]\n",
    "    for i in range(5, 10):\n",
    "        lo = df[df['actionType'] == i].reset_index().groupby('userid').nth(-1).reset_index()[['userid', 'index']]\n",
    "        hi = df.reset_index().groupby('userid').nth(-1).reset_index()[['userid', 'index']]\n",
    "        lo_hi = pd.merge(lo, hi, how='left', on='userid')\n",
    "        lo_hi.columns = ['userid', 'lo_ind', 'hi_ind']\n",
    "        index_list = []\n",
    "        for index, row in lo_hi.iterrows():\n",
    "            index_list += range(row['lo_ind'], row['hi_ind'] + 1)\n",
    "        tmp = df.iloc[index_list,:]\n",
    "        tmp = tmp.groupby('userid')['time_gap'].std().reset_index()\n",
    "        tmp.columns = ['userid', 'time_gap_seq' + str(i) + '_std']\n",
    "        time_gap_seq_stat = pd.merge(time_gap_seq_stat, tmp, how='left', on='userid')\n",
    "\n",
    "    for i in [2, 3, 5, 6, 7, 8, 9]:\n",
    "        lo = df[df['actionType'] == i].reset_index().groupby('userid').nth(-1).reset_index()[['userid', 'index']]\n",
    "        hi = df.reset_index().groupby('userid').nth(-1).reset_index()[['userid', 'index']]\n",
    "        lo_hi = pd.merge(lo, hi, how='left', on='userid')\n",
    "        lo_hi.columns = ['userid', 'lo_ind', 'hi_ind']\n",
    "        index_list = []\n",
    "        for index, row in lo_hi.iterrows():\n",
    "            index_list += range(row['lo_ind'], row['hi_ind'] + 1)\n",
    "        tmp = df.iloc[index_list,:]\n",
    "        tmp = tmp.groupby('userid')['time_gap'].mean().reset_index()\n",
    "        tmp.columns = ['userid', 'time_gap_seq' + str(i) + '_mean']\n",
    "        time_gap_seq_stat = pd.merge(time_gap_seq_stat, tmp, how='left', on='userid')\n",
    "\n",
    "    for i in [2, 3, 4, 5, 6, 7, 8]:\n",
    "        lo = df[df['actionType'] == i].reset_index().groupby('userid').nth(-1).reset_index()[['userid', 'index']]\n",
    "        hi = df.reset_index().groupby('userid').nth(-1).reset_index()[['userid', 'index']]\n",
    "        lo_hi = pd.merge(lo, hi, how='left', on='userid')\n",
    "        lo_hi.columns = ['userid', 'lo_ind', 'hi_ind']\n",
    "        index_list = []\n",
    "        for index, row in lo_hi.iterrows():\n",
    "            index_list += range(row['lo_ind'], row['hi_ind'] + 1)\n",
    "        tmp = df.iloc[index_list,:]\n",
    "        tmp = tmp.groupby('userid')['time_gap'].min().reset_index()\n",
    "        tmp.columns = ['userid', 'time_gap_seq' + str(i) + '_min']\n",
    "        time_gap_seq_stat = pd.merge(time_gap_seq_stat, tmp, how='left', on='userid')\n",
    "\n",
    "    for i in [5, 6, 7]:\n",
    "        lo = df[df['actionType'] == i].reset_index().groupby('userid').nth(-1).reset_index()[['userid', 'index']]\n",
    "        hi = df.reset_index().groupby('userid').nth(-1).reset_index()[['userid', 'index']]\n",
    "        lo_hi = pd.merge(lo, hi, how='left', on='userid')\n",
    "        lo_hi.columns = ['userid', 'lo_ind', 'hi_ind']\n",
    "        index_list = []\n",
    "        for index, row in lo_hi.iterrows():\n",
    "            index_list += range(row['lo_ind'], row['hi_ind'] + 1)\n",
    "        tmp = df.iloc[index_list,:]\n",
    "        tmp = tmp.groupby('userid')['time_gap'].max().reset_index()\n",
    "        tmp.columns = ['userid', 'time_gap_seq' + str(i) + '_max']\n",
    "        time_gap_seq_stat = pd.merge(time_gap_seq_stat, tmp, how='left', on='userid')\n",
    "\n",
    "    time_gap_seq_stat['time_gap_seq9_mean*std'] = time_gap_seq_stat['time_gap_seq9_mean'] * time_gap_seq_stat['time_gap_seq9_std']\n",
    "\n",
    "    type_rate = mydf.copy()\n",
    "    for i in range(1, 10):\n",
    "        tmp = df[df['actionType'] == i].groupby('userid').size().reset_index()\n",
    "        tmp.columns = ['userid', 'type' + str(i) + '_rate']\n",
    "        type_rate = pd.merge(type_rate, tmp, how='left', on='userid')\n",
    "        type_rate['type' + str(i) + '_rate'] = type_rate['type' + str(i) + '_rate'] / type_rate['action_num']\n",
    "    type_rate = type_rate.drop('action_num', axis=1)\n",
    "\n",
    "    mydf = pd.merge(mydf, act_type_last, how='left', on='userid')\n",
    "    mydf = pd.merge(mydf, act_type_first1, how='left', on='userid')\n",
    "    mydf = pd.merge(mydf, time_gap_stat, how='left', on='userid')\n",
    "    mydf = pd.merge(mydf, time_gap_last, how='left', on='userid')\n",
    "    mydf = pd.merge(mydf, time_gap_first1, how='left', on='userid')\n",
    "    mydf = pd.merge(mydf, time_gap_last123, how='left', on='userid')\n",
    "    mydf = pd.merge(mydf, dist, how='left', on='userid')\n",
    "    mydf = pd.merge(mydf, time_gap_all_type, how='left', on='userid')\n",
    "    mydf = pd.merge(mydf, time_gap_seq_stat, how='left', on='userid')\n",
    "    mydf = pd.merge(mydf, type_rate, how='left', on='userid')\n",
    "\n",
    "    mydf = mydf.drop('action_num', axis=1)\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_comment_feature(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    \n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_order_history_feature(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    mydf = df.groupby('userid')['orderType'].max().reset_index()\n",
    "    mydf.columns = ['userid', 'if_order']\n",
    "\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile_feat_tr = get_user_profile_feature(user_profile_tr)\n",
    "action_feat_tr = get_action_feature(action_tr)\n",
    "order_history_feat_tr = get_order_history_feature(order_history_tr)\n",
    "\n",
    "dataset_tr = pd.merge(user_profile_feat_tr, action_feat_tr, on='userid', how='left')\n",
    "dataset_tr = pd.merge(dataset_tr, order_history_feat_tr, on='userid', how='left')\n",
    "\n",
    "trainset = pd.merge(order_future_tr, dataset_tr, on='userid', how='left')\n",
    "\n",
    "train_feature = trainset.drop(['userid', 'orderType'], axis=1)\n",
    "train_label = trainset.orderType.values\n",
    "\n",
    "print train_feature.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile_feat_te = get_user_profile_feature(user_profile_te)\n",
    "action_feat_te = get_action_feature(action_te)\n",
    "order_history_feat_te = get_order_history_feature(order_history_te)\n",
    "\n",
    "dataset_te = pd.merge(user_profile_feat_te, action_feat_te, on='userid', how='left')\n",
    "dataset_te = pd.merge(dataset_te, order_history_feat_te, on='userid', how='left')\n",
    "\n",
    "testset = pd.merge(order_future_te, dataset_te, on='userid', how='left')\n",
    "\n",
    "test_feature = testset.drop(['userid'], axis=1)\n",
    "test_index = testset.userid.values\n",
    "\n",
    "print test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'rounds': 10000,\n",
    "    'folds': 5\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'stratified': True,\n",
    "    'scale_pos_weights ': 0,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'subsample': 0.75,\n",
    "    'colsample_bytree': 0.75,\n",
    "    'lambda': 1,\n",
    "\n",
    "    'eta': 0.02,\n",
    "    'seed': 20,\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_cv(train_feature, train_label, params, folds, rounds):\n",
    "    start = time.clock()\n",
    "    print train_feature.columns\n",
    "    params['scale_pos_weights '] = float(len(train_label[train_label == 0])) / len(train_label[train_label == 1])\n",
    "    dtrain = xgb.DMatrix(train_feature, label=train_label)\n",
    "    num_round = rounds\n",
    "    print 'run cv: ' + 'round: ' + str(rounds)\n",
    "    res = xgb.cv(params, dtrain, num_round, nfold=folds, verbose_eval=10, early_stopping_rounds=100)\n",
    "    elapsed = (time.clock() - start)\n",
    "    print 'Time used:', elapsed, 's'\n",
    "    return len(res), res.loc[len(res) - 1, 'test-auc-mean']\n",
    "\n",
    "\n",
    "def xgb_predict(train_feature, train_label, test_feature, rounds, params):\n",
    "    params['scale_pos_weights '] = float(len(train_label[train_label == 0])) / len(train_label[train_label == 1])\n",
    "    dtrain = xgb.DMatrix(train_feature, label=train_label)\n",
    "    dtest = xgb.DMatrix(test_feature, label=np.zeros(test_feature.shape[0]))\n",
    "    watchlist = [(dtrain, 'train')]\n",
    "    num_round = rounds\n",
    "    model = xgb.train(params, dtrain, num_round, watchlist, verbose_eval=30)\n",
    "    predict = model.predict(dtest)\n",
    "    return model, predict\n",
    "\n",
    "\n",
    "def store_result(test_index, pred, name):\n",
    "    result = pd.DataFrame({'userid': test_index, 'orderType': pred})\n",
    "    result.to_csv('../data/output/sub/' + name + '.csv', index=0, columns=['userid', 'orderType'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations, best_score = xgb_cv(train_feature, train_label, params, config['folds'], config['rounds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(600,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, pred = xgb_predict(train_feature, train_label, test_feature, iterations, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(model.get_fscore().items(), columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "importance.to_csv('../data/output/feat_imp/importance-20180112-%f(r%d).csv' % (best_score, iterations), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = store_result(test_index, pred, '20180112-xgb-%f(r%d)' % (best_score, iterations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
